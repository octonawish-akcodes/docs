{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"K8sGPT Documentation K8sGPT gives Kubernetes SRE superpowers to everyone The documentation provides the following Getting started: Guides to install and use K8sGPT Tutorials: End-to-end tutorials on specific use cases Reference: Specific documentation on the features Explanation: Additional explanations on the design and use of the CLI Documentation enhancements If anything is unclear please create an issue in the docs repository.","title":"Overview"},{"location":"#k8sgpt-documentation","text":"K8sGPT gives Kubernetes SRE superpowers to everyone The documentation provides the following Getting started: Guides to install and use K8sGPT Tutorials: End-to-end tutorials on specific use cases Reference: Specific documentation on the features Explanation: Additional explanations on the design and use of the CLI","title":"K8sGPT Documentation"},{"location":"#documentation-enhancements","text":"If anything is unclear please create an issue in the docs repository.","title":"Documentation enhancements"},{"location":"explanation/","text":"Explanation This section will provide detailed information on different K8sGPT components, including decisions on design architecture development and more","title":"Explanation"},{"location":"explanation/#explanation","text":"This section will provide detailed information on different K8sGPT components, including decisions on design architecture development and more","title":"Explanation"},{"location":"getting-started/getting-started/","text":"Getting Started Guide Prerequisites Ensure k8sgpt is installed correctly on your environment by following the installation . You need to be connected to any Kubernetes cluster. Setting up a Kubernetes cluster To give 'k8sgpt` a try, set up a basic KinD Kubernetes cluster if you are not connected to any other cluster. Please only use K8sGPT on environments XXX The KinD documentation provides several installation options to set up a local cluster with two commands. Using K8sGPT You can view the different command options through k8sgpt --help Kubernetes debugging powered by AI Usage: k8sgpt [command] Available Commands: analyze This command will find problems within your Kubernetes cluster auth Authenticate with your chosen backend completion Generate the autocompletion script for the specified shell generate Generate Key for your chosen backend (opens browser) help Help about any command version Print the version number of k8sgpt Flags: --config string config file (default is $HOME/.k8sgpt.yaml) -h, --help help for k8sgpt --kubeconfig string Path to a kubeconfig. Only required if out-of-cluster. --master string The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster. -t, --toggle Help message for toggle Use \"k8sgpt [command] --help\" for more information about a command. Authenticate with ChatGPT First, you will need to authenticate with your chosen backend. The backend is the AI provider such as OpenAI's ChatGPT. Ensure that you have created an account. Next, generate a token from the backend: k8sgpt generate This will provide you with a URL to generate a token, follow the URL from the commandline to your browser to then generate the token. Copy the token for the next step. Then, authenticate with the following command: k8sgpt auth This will request the token that has just been generated. Paste the token into the commandline. You should then see the following success message: Enter openai Key: key added Analyse your cluster Ensure that you are connected to a Kubernetes cluster: kubectl get nodes Next, you can go ahead an analyse your cluster: k8sgpt analyse This will provide you with a list of issues of your Kubernetes cluster.","title":"Getting Started Guide"},{"location":"getting-started/getting-started/#getting-started-guide","text":"","title":"Getting Started Guide"},{"location":"getting-started/getting-started/#prerequisites","text":"Ensure k8sgpt is installed correctly on your environment by following the installation . You need to be connected to any Kubernetes cluster.","title":"Prerequisites"},{"location":"getting-started/getting-started/#setting-up-a-kubernetes-cluster","text":"To give 'k8sgpt` a try, set up a basic KinD Kubernetes cluster if you are not connected to any other cluster. Please only use K8sGPT on environments XXX The KinD documentation provides several installation options to set up a local cluster with two commands.","title":"Setting up a Kubernetes cluster"},{"location":"getting-started/getting-started/#using-k8sgpt","text":"You can view the different command options through k8sgpt --help Kubernetes debugging powered by AI Usage: k8sgpt [command] Available Commands: analyze This command will find problems within your Kubernetes cluster auth Authenticate with your chosen backend completion Generate the autocompletion script for the specified shell generate Generate Key for your chosen backend (opens browser) help Help about any command version Print the version number of k8sgpt Flags: --config string config file (default is $HOME/.k8sgpt.yaml) -h, --help help for k8sgpt --kubeconfig string Path to a kubeconfig. Only required if out-of-cluster. --master string The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster. -t, --toggle Help message for toggle Use \"k8sgpt [command] --help\" for more information about a command.","title":"Using K8sGPT"},{"location":"getting-started/getting-started/#authenticate-with-chatgpt","text":"First, you will need to authenticate with your chosen backend. The backend is the AI provider such as OpenAI's ChatGPT. Ensure that you have created an account. Next, generate a token from the backend: k8sgpt generate This will provide you with a URL to generate a token, follow the URL from the commandline to your browser to then generate the token. Copy the token for the next step. Then, authenticate with the following command: k8sgpt auth This will request the token that has just been generated. Paste the token into the commandline. You should then see the following success message: Enter openai Key: key added","title":"Authenticate with ChatGPT"},{"location":"getting-started/getting-started/#analyse-your-cluster","text":"Ensure that you are connected to a Kubernetes cluster: kubectl get nodes Next, you can go ahead an analyse your cluster: k8sgpt analyse This will provide you with a list of issues of your Kubernetes cluster.","title":"Analyse your cluster"},{"location":"getting-started/in-cluster-operator/","text":"K8sGPT Operator Prerequisites To begin you will require a Kubernetes cluster available and KUBECONFIG set. You will also need to install helm v3. See the Helm documentation for more information . Operator Installation To install the operator, run the following command: helm repo add k8sgpt https://charts.k8sgpt.ai/ helm repo update helm install release k8sgpt/k8sgpt-operator -n k8sgpt-operator-system --create-namespace This will install the Operator into the cluster, which will await a K8sGPT resource before anything happens. Deploying an OpenAI secret Whilst there are multiple backends supported ( OpenAI, Azure OpenAI and Local ), in this example we'll use OpenAI. Whatever backend you are using, you need to make sure to have a secret that works with the backend. For instance, this means you will need to install your OpenAI token as a secret into the cluster: kubectl create secret generic k8sgpt-sample-secret --from-literal=openai-api-key=$OPENAI_TOKEN -n default Deploying a K8sGPT resource To deploy a K8sGPT resource, you will need to create a YAML file with the following contents: kubectl apply -f - << EOF apiVersion: core.k8sgpt.ai/v1alpha1 kind: K8sGPT metadata: name: k8sgpt-sample spec: namespace: default model: gpt-3.5-turbo backend: openai noCache: false version: v0.3.0 enableAI: true secret: name: k8sgpt-sample-secret key: openai-api-key EOF Regarding out of cluster traffic to AI backends In the above example enableAI is set to true . This option allows the cluster deployment to use the backend to filter and improve the responses to the user. Those responses will appear as details within the Result custom resources that are created. The default backend in this example is OpenAI and allows for additional details to be generated and solutions provided for issues. If you wish to disable out-of-cluster communication and any Artificial Intelligence processing through models, simply set enableAI to false . It should also be noted that localai is supported and in-cluster models will be supported in the near future Viewing the results Once the initial scans have completed after several minutes, you will be presented with results custom resources. \u276f kubectl get results -o json | jq . { \"apiVersion\": \"v1\", \"items\": [ { \"apiVersion\": \"core.k8sgpt.ai/v1alpha1\", \"kind\": \"Result\", \"metadata\": { \"creationTimestamp\": \"2023-04-26T09:45:02Z\", \"generation\": 1, \"name\": \"placementoperatorsystemplacementoperatorcontrollermanagermetricsservice\", \"namespace\": \"default\", \"resourceVersion\": \"108371\", \"uid\": \"f0edd4de-92b6-4de2-ac86-5bb2b2da9736\" }, \"spec\": { \"details\": \"The error message means that the service in Kubernetes doesn't have any associated endpoints, which should have been labeled with \\\"control-plane=controller-manager\\\". \\n\\nTo solve this issue, you need to add the \\\"control-plane=controller-manager\\\" label to the endpoint that matches the service. Once the endpoint is labeled correctly, Kubernetes can associate it with the service, and the error should be resolved.\", ...","title":"In-Cluster Operator"},{"location":"getting-started/in-cluster-operator/#k8sgpt-operator","text":"","title":"K8sGPT Operator"},{"location":"getting-started/in-cluster-operator/#prerequisites","text":"To begin you will require a Kubernetes cluster available and KUBECONFIG set. You will also need to install helm v3. See the Helm documentation for more information .","title":"Prerequisites"},{"location":"getting-started/in-cluster-operator/#operator-installation","text":"To install the operator, run the following command: helm repo add k8sgpt https://charts.k8sgpt.ai/ helm repo update helm install release k8sgpt/k8sgpt-operator -n k8sgpt-operator-system --create-namespace This will install the Operator into the cluster, which will await a K8sGPT resource before anything happens.","title":"Operator Installation"},{"location":"getting-started/in-cluster-operator/#deploying-an-openai-secret","text":"Whilst there are multiple backends supported ( OpenAI, Azure OpenAI and Local ), in this example we'll use OpenAI. Whatever backend you are using, you need to make sure to have a secret that works with the backend. For instance, this means you will need to install your OpenAI token as a secret into the cluster: kubectl create secret generic k8sgpt-sample-secret --from-literal=openai-api-key=$OPENAI_TOKEN -n default","title":"Deploying an OpenAI secret"},{"location":"getting-started/in-cluster-operator/#deploying-a-k8sgpt-resource","text":"To deploy a K8sGPT resource, you will need to create a YAML file with the following contents: kubectl apply -f - << EOF apiVersion: core.k8sgpt.ai/v1alpha1 kind: K8sGPT metadata: name: k8sgpt-sample spec: namespace: default model: gpt-3.5-turbo backend: openai noCache: false version: v0.3.0 enableAI: true secret: name: k8sgpt-sample-secret key: openai-api-key EOF","title":"Deploying a K8sGPT resource"},{"location":"getting-started/in-cluster-operator/#regarding-out-of-cluster-traffic-to-ai-backends","text":"In the above example enableAI is set to true . This option allows the cluster deployment to use the backend to filter and improve the responses to the user. Those responses will appear as details within the Result custom resources that are created. The default backend in this example is OpenAI and allows for additional details to be generated and solutions provided for issues. If you wish to disable out-of-cluster communication and any Artificial Intelligence processing through models, simply set enableAI to false . It should also be noted that localai is supported and in-cluster models will be supported in the near future","title":"Regarding out of cluster traffic to AI backends"},{"location":"getting-started/in-cluster-operator/#viewing-the-results","text":"Once the initial scans have completed after several minutes, you will be presented with results custom resources. \u276f kubectl get results -o json | jq . { \"apiVersion\": \"v1\", \"items\": [ { \"apiVersion\": \"core.k8sgpt.ai/v1alpha1\", \"kind\": \"Result\", \"metadata\": { \"creationTimestamp\": \"2023-04-26T09:45:02Z\", \"generation\": 1, \"name\": \"placementoperatorsystemplacementoperatorcontrollermanagermetricsservice\", \"namespace\": \"default\", \"resourceVersion\": \"108371\", \"uid\": \"f0edd4de-92b6-4de2-ac86-5bb2b2da9736\" }, \"spec\": { \"details\": \"The error message means that the service in Kubernetes doesn't have any associated endpoints, which should have been labeled with \\\"control-plane=controller-manager\\\". \\n\\nTo solve this issue, you need to add the \\\"control-plane=controller-manager\\\" label to the endpoint that matches the service. Once the endpoint is labeled correctly, Kubernetes can associate it with the service, and the error should be resolved.\", ...","title":"Viewing the results"},{"location":"getting-started/installation/","text":"Installation This page provides further information on installation guidelines. Linux/Mac via brew Prerequisites Ensure that you have Homebrew installed: Homebrew for Mac Homebrew for Linux Homebrew for Linux also works on WSL Homebrew Install K8sGPT on your machine with the following commands: brew tap k8sgpt-ai/k8sgpt brew install k8sgpt Other Installation Options RPM-based installation (RedHat/CentOS/Fedora) 32 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.1/k8sgpt_386.rpm sudo rpm -ivh k8sgpt_386.rpm 64 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.1/k8sgpt_amd64.rpm sudo rpm -ivh -i k8sgpt_amd64.rpm DEB-based installation (Ubuntu/Debian) 32 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.7/k8sgpt_386.deb sudo dpkg -i k8sgpt_386.deb 64 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.7/k8sgpt_amd64.deb sudo dpkg -i k8sgpt_amd64.deb APK-based installation (Alpine) 32 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.7/k8sgpt_386.apk apk add k8sgpt_386.apk 64 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.1/k8sgpt_amd64.apk apk add k8sgpt_amd64.apk Windows Download the latest Windows binaries of k8sgpt from the Release tab based on your system architecture. Extract the downloaded package to your desired location. Configure the system path variable with the binary location Verify installation Verify that K8sGPT is installed correctly: k8sgpt version k8sgpt version 0.2.7 Common Issues Windows WSL Failing Installation on WSL or Linux (missing gcc) When installing Homebrew on WSL or Linux, you may encounter the following error: ==> Installing k8sgpt from k8sgpt-ai/k8sgpt Error: The following formula cannot be installed from bottle and must be built from source. k8sgpt Install Clang or run brew install gcc. If you install gcc as suggested, the problem will persist. Therefore, you need to install the build-essential package. sudo apt-get update sudo apt-get install build-essential Failing Installation on WSL or Linux (missing gcc) When installing Homebrew on WSL or Linux, you may encounter the following error: ==> Installing k8sgpt from k8sgpt-ai/k8sgpt Error: The following formula cannot be installed from a bottle and must be built from the source. k8sgpt Install Clang or run brew install gcc. If you install gcc as suggested, the problem will persist. Therefore, you need to install the build-essential package. bash sudo apt-get update sudo apt-get install build-essential Running K8sGPT through a container If you are running K8sGPT through a container, the CLI will not be able to open the website for the OpenAI token. You can find the latest container image for K8sGPT in the packages of the GitHub organisation: Link A volume can then be mounted to the image through e.g. Docker Compose . Below is an example: version: '2' services: k8sgpt: image: ghcr.io/k8sgpt-ai/k8sgpt:dev-202304011623 volumes: - /home/$(whoami)/.k8sgpt.yaml:/home/root/.k8sgpt.yaml Installing the K8sGPT Operator Helm Chart K8sGPT can be installed as an Operator inside the cluster. For further information, see the K8sGPT Operator documentation. Upgrading the brew installation To upgrade the K8sGPT brew installation run the following command: brew upgrade k8sgpt","title":"Installation"},{"location":"getting-started/installation/#installation","text":"This page provides further information on installation guidelines.","title":"Installation"},{"location":"getting-started/installation/#linuxmac-via-brew","text":"","title":"Linux/Mac via brew"},{"location":"getting-started/installation/#prerequisites","text":"Ensure that you have Homebrew installed: Homebrew for Mac Homebrew for Linux Homebrew for Linux also works on WSL","title":"Prerequisites"},{"location":"getting-started/installation/#homebrew","text":"Install K8sGPT on your machine with the following commands: brew tap k8sgpt-ai/k8sgpt brew install k8sgpt","title":"Homebrew"},{"location":"getting-started/installation/#other-installation-options","text":"","title":"Other Installation Options"},{"location":"getting-started/installation/#rpm-based-installation-redhatcentosfedora","text":"32 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.1/k8sgpt_386.rpm sudo rpm -ivh k8sgpt_386.rpm 64 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.1/k8sgpt_amd64.rpm sudo rpm -ivh -i k8sgpt_amd64.rpm","title":"RPM-based installation (RedHat/CentOS/Fedora)"},{"location":"getting-started/installation/#deb-based-installation-ubuntudebian","text":"32 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.7/k8sgpt_386.deb sudo dpkg -i k8sgpt_386.deb 64 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.7/k8sgpt_amd64.deb sudo dpkg -i k8sgpt_amd64.deb","title":"DEB-based installation (Ubuntu/Debian)"},{"location":"getting-started/installation/#apk-based-installation-alpine","text":"32 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.7/k8sgpt_386.apk apk add k8sgpt_386.apk 64 bit: curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.2.1/k8sgpt_amd64.apk apk add k8sgpt_amd64.apk","title":"APK-based installation (Alpine)"},{"location":"getting-started/installation/#windows","text":"Download the latest Windows binaries of k8sgpt from the Release tab based on your system architecture. Extract the downloaded package to your desired location. Configure the system path variable with the binary location","title":"Windows"},{"location":"getting-started/installation/#verify-installation","text":"Verify that K8sGPT is installed correctly: k8sgpt version k8sgpt version 0.2.7","title":"Verify installation"},{"location":"getting-started/installation/#common-issues","text":"","title":"Common Issues"},{"location":"getting-started/installation/#windows-wsl","text":"Failing Installation on WSL or Linux (missing gcc) When installing Homebrew on WSL or Linux, you may encounter the following error: ==> Installing k8sgpt from k8sgpt-ai/k8sgpt Error: The following formula cannot be installed from bottle and must be built from source. k8sgpt Install Clang or run brew install gcc. If you install gcc as suggested, the problem will persist. Therefore, you need to install the build-essential package. sudo apt-get update sudo apt-get install build-essential","title":"Windows WSL"},{"location":"getting-started/installation/#failing-installation-on-wsl-or-linux-missing-gcc","text":"When installing Homebrew on WSL or Linux, you may encounter the following error: ==> Installing k8sgpt from k8sgpt-ai/k8sgpt Error: The following formula cannot be installed from a bottle and must be built from the source. k8sgpt Install Clang or run brew install gcc. If you install gcc as suggested, the problem will persist. Therefore, you need to install the build-essential package. bash sudo apt-get update sudo apt-get install build-essential","title":"Failing Installation on WSL or Linux (missing gcc)"},{"location":"getting-started/installation/#running-k8sgpt-through-a-container","text":"If you are running K8sGPT through a container, the CLI will not be able to open the website for the OpenAI token. You can find the latest container image for K8sGPT in the packages of the GitHub organisation: Link A volume can then be mounted to the image through e.g. Docker Compose . Below is an example: version: '2' services: k8sgpt: image: ghcr.io/k8sgpt-ai/k8sgpt:dev-202304011623 volumes: - /home/$(whoami)/.k8sgpt.yaml:/home/root/.k8sgpt.yaml","title":"Running K8sGPT through a container"},{"location":"getting-started/installation/#installing-the-k8sgpt-operator-helm-chart","text":"K8sGPT can be installed as an Operator inside the cluster. For further information, see the K8sGPT Operator documentation.","title":"Installing the K8sGPT Operator Helm Chart"},{"location":"getting-started/installation/#upgrading-the-brew-installation","text":"To upgrade the K8sGPT brew installation run the following command: brew upgrade k8sgpt","title":"Upgrading the brew installation"},{"location":"reference/cli/","text":"CLI Reference This section provides an overview of the different k8sgpt CLI commands. Prerequisites * You need to be connected to a Kubernetes cluster, K8sGPT will access it through your kubeconfig. * Signed-up to OpenAI ChatGPT * Have the K8sGPT CLI installed Commands Generate Command: k8sgpt generate This command will provide you with a URL to OpenAI to generate an access token. Auth Command: k8sgpt auth This command authenticates you with your chosen backend. Provide the access token generated through the generate command here. Analyze Command: k8sgpt analyse This command will find problems within your Kubernetes cluster. Completion Command: k8sgpt completion Generate the autocompletion script for the specified shell. Help Command: k8sgpt help Provides you with the different command options in the CLI. Version Command: k8sgpt version Prints the K8sGPT version you are using. Flags --config Define the path to your k8sgpt configuration file: --config string The default is located at $HOME/.k8sgpt.yaml --help Access more information on the different commands: -h, --help --kubeconfig Provide the Path to your KubeConfig: --kubeconfig string --kubecontext You can be connected to multiple Kubernetes context. To specify the Kubernetes context, use the following flag: --kubecontext string","title":"Overview"},{"location":"reference/cli/#cli-reference","text":"This section provides an overview of the different k8sgpt CLI commands. Prerequisites * You need to be connected to a Kubernetes cluster, K8sGPT will access it through your kubeconfig. * Signed-up to OpenAI ChatGPT * Have the K8sGPT CLI installed","title":"CLI Reference"},{"location":"reference/cli/#commands","text":"","title":"Commands"},{"location":"reference/cli/#generate","text":"Command: k8sgpt generate This command will provide you with a URL to OpenAI to generate an access token.","title":"Generate"},{"location":"reference/cli/#auth","text":"Command: k8sgpt auth This command authenticates you with your chosen backend. Provide the access token generated through the generate command here.","title":"Auth"},{"location":"reference/cli/#analyze","text":"Command: k8sgpt analyse This command will find problems within your Kubernetes cluster.","title":"Analyze"},{"location":"reference/cli/#completion","text":"Command: k8sgpt completion Generate the autocompletion script for the specified shell.","title":"Completion"},{"location":"reference/cli/#help","text":"Command: k8sgpt help Provides you with the different command options in the CLI.","title":"Help"},{"location":"reference/cli/#version","text":"Command: k8sgpt version Prints the K8sGPT version you are using.","title":"Version"},{"location":"reference/cli/#flags","text":"","title":"Flags"},{"location":"reference/cli/#-config","text":"Define the path to your k8sgpt configuration file: --config string The default is located at $HOME/.k8sgpt.yaml","title":"--config"},{"location":"reference/cli/#-help","text":"Access more information on the different commands: -h, --help","title":"--help"},{"location":"reference/cli/#-kubeconfig","text":"Provide the Path to your KubeConfig: --kubeconfig string","title":"--kubeconfig"},{"location":"reference/cli/#-kubecontext","text":"You can be connected to multiple Kubernetes context. To specify the Kubernetes context, use the following flag: --kubecontext string","title":"--kubecontext"},{"location":"reference/cli/filters/","text":"Using Integration and Filters in K8sGPT K8sGPT offers integration with other tools. Once an integration is added to K8sGPT, it is possible to use its resources as additional filters. Filters are a way of selecting which resources you wish to be part of your default analysis. Integrations are a way to add in additional resources to the filter list. The first integration that has been added is Trivy. Trivy is an open source, cloud native security scnaner, maintained by Aqua Security. Use the following command to access all K8sGPT CLI options related to integrations: k8sgpt integrations Activating a new integration Prerequisites Connected to a running Kubernetes cluster, any cluster will work for demonstration purposes To list all integrations run the following command: k8sgpt integrations list This will provide you with a list of available integrations. Activate the Trivy integration: k8sgpt integration activate trivy This will install the Trivy Kubernetes Operator into the Kubernetes cluster and make it possible for K8sGPT to interact with the results of the Operator. Once the Trivy Operator is installed inside the cluster, K8sGPT will have access to VulnerabilityReports: k8sgpt filters list Active: > VulnerabilityReport (integration) Unused: > Pod > Deployment > Service > StatefulSet > ReplicaSet > PersistentVolumeClaim > Ingress > CronJob > Node > NetworkPolicy > HorizontalPodAutoScaler > PodDisruptionBudget Using the new filters to analyse your cluster Any of the filters listed in the previous section can be used as part of the k8sgpt analyse command. To use the VulnerabilityReport filter from the Trivy integration, set it through the --filter flag: k8sgpt analyse --filter VulnerabilityReport This command will analyse your cluster Vulnerabilities through K8sGPT. Depnding on the VulnerabilityReports available in your cluster, the result of the report will look different: \u276f k8sgpt analyse --filter VulnerabilityReport 0 demo/nginx-deployment-7bcfc88bbf(Deployment/nginx-deployment) - Error: critical Vulnerability found ID: CVE-2023-23914 (learn more at: https://avd.aquasec.com/nvd/cve-2023-23914) - Error: critical Vulnerability found ID: CVE-2023-27536 (learn more at: https://avd.aquasec.com/nvd/cve-2023-27536) - Error: critical Vulnerability found ID: CVE-2023-23914 (learn more at: https://avd.aquasec.com/nvd/cve-2023-23914) - Error: critical Vulnerability found ID: CVE-2023-27536 (learn more at: https://avd.aquasec.com/nvd/cve-2023-27536) - Error: critical Vulnerability found ID: CVE-2019-8457 (learn more at: https://avd.aquasec.com/nvd/cve-2019-8457)","title":"Integration and Filter"},{"location":"reference/cli/filters/#using-integration-and-filters-in-k8sgpt","text":"K8sGPT offers integration with other tools. Once an integration is added to K8sGPT, it is possible to use its resources as additional filters. Filters are a way of selecting which resources you wish to be part of your default analysis. Integrations are a way to add in additional resources to the filter list. The first integration that has been added is Trivy. Trivy is an open source, cloud native security scnaner, maintained by Aqua Security. Use the following command to access all K8sGPT CLI options related to integrations: k8sgpt integrations","title":"Using Integration and Filters in K8sGPT"},{"location":"reference/cli/filters/#activating-a-new-integration","text":"Prerequisites Connected to a running Kubernetes cluster, any cluster will work for demonstration purposes To list all integrations run the following command: k8sgpt integrations list This will provide you with a list of available integrations. Activate the Trivy integration: k8sgpt integration activate trivy This will install the Trivy Kubernetes Operator into the Kubernetes cluster and make it possible for K8sGPT to interact with the results of the Operator. Once the Trivy Operator is installed inside the cluster, K8sGPT will have access to VulnerabilityReports: k8sgpt filters list Active: > VulnerabilityReport (integration) Unused: > Pod > Deployment > Service > StatefulSet > ReplicaSet > PersistentVolumeClaim > Ingress > CronJob > Node > NetworkPolicy > HorizontalPodAutoScaler > PodDisruptionBudget","title":"Activating a new integration"},{"location":"reference/cli/filters/#using-the-new-filters-to-analyse-your-cluster","text":"Any of the filters listed in the previous section can be used as part of the k8sgpt analyse command. To use the VulnerabilityReport filter from the Trivy integration, set it through the --filter flag: k8sgpt analyse --filter VulnerabilityReport This command will analyse your cluster Vulnerabilities through K8sGPT. Depnding on the VulnerabilityReports available in your cluster, the result of the report will look different: \u276f k8sgpt analyse --filter VulnerabilityReport 0 demo/nginx-deployment-7bcfc88bbf(Deployment/nginx-deployment) - Error: critical Vulnerability found ID: CVE-2023-23914 (learn more at: https://avd.aquasec.com/nvd/cve-2023-23914) - Error: critical Vulnerability found ID: CVE-2023-27536 (learn more at: https://avd.aquasec.com/nvd/cve-2023-27536) - Error: critical Vulnerability found ID: CVE-2023-23914 (learn more at: https://avd.aquasec.com/nvd/cve-2023-23914) - Error: critical Vulnerability found ID: CVE-2023-27536 (learn more at: https://avd.aquasec.com/nvd/cve-2023-27536) - Error: critical Vulnerability found ID: CVE-2019-8457 (learn more at: https://avd.aquasec.com/nvd/cve-2019-8457)","title":"Using the new filters to analyse your cluster"},{"location":"reference/guidelines/community/","text":"Community Information All community related information are kept in a separate repository from the docs. Link to the repository: k8sgpt-ai/community There you will find information on The Charter Adopters List Code of Conduct Community Members Subprojects and much more.","title":"Community"},{"location":"reference/guidelines/community/#community-information","text":"All community related information are kept in a separate repository from the docs. Link to the repository: k8sgpt-ai/community There you will find information on The Charter Adopters List Code of Conduct Community Members Subprojects and much more.","title":"Community Information"},{"location":"reference/guidelines/guidelines/","text":"Contributing Guidelines Contributing to the Documentation This documentation follows the Diataxis framework. If you are proposing completely new content to the documentation, please familiarise yourself with the framework first. The documentation is created with mkdocs , specifically the Material for MkDocs theme . Contributing projects in the K8sGPT organisation All project in the K8sGPT organisation follow our contributing guidelines.","title":"Guidelines"},{"location":"reference/guidelines/guidelines/#contributing-guidelines","text":"","title":"Contributing Guidelines"},{"location":"reference/guidelines/guidelines/#contributing-to-the-documentation","text":"This documentation follows the Diataxis framework. If you are proposing completely new content to the documentation, please familiarise yourself with the framework first. The documentation is created with mkdocs , specifically the Material for MkDocs theme .","title":"Contributing to the Documentation"},{"location":"reference/guidelines/guidelines/#contributing-projects-in-the-k8sgpt-organisation","text":"All project in the K8sGPT organisation follow our contributing guidelines.","title":"Contributing projects in the K8sGPT organisation"},{"location":"reference/guidelines/privacy/","text":"Privacy K8sGPT is a privacy-first tool and believe transparency is key for you to understand how we use your data. We have created this page to help you understand how we collect, use, share and protect your data. Data we collect K8sGPT will collect data from Analyzers and either display it directly to you or with the --explain flag it will send it to the selected AI backend. The type of data collected depends on the Analyzer you are using. For example, the k8sgpt analyze pod command will collect the following data: - Container status message - Pod name - Pod namespace - Event message Data we share As mentioned, K8sGPT will share data with the selected AI backend only when you choose --explain and auth against that backend. The data shared will be the same as the data collected. To learn more about the privacy policy of our default AI backend OpenAI please visit their privacy policy . Data we protect When you are sending data through the --explain option, there is the capability of anonymising some of that data. This is done by using the --anonymise flag. In the example of the Deployment Analyzer, this will obfusicate the following data: Deployment name Deployment namespace Data we don't collect Logs API Server data other than the primitives used within our Analyzers. Contact If you have any questions about our privacy policy, please contact us .","title":"Privacy"},{"location":"reference/guidelines/privacy/#privacy","text":"K8sGPT is a privacy-first tool and believe transparency is key for you to understand how we use your data. We have created this page to help you understand how we collect, use, share and protect your data.","title":"Privacy"},{"location":"reference/guidelines/privacy/#data-we-collect","text":"K8sGPT will collect data from Analyzers and either display it directly to you or with the --explain flag it will send it to the selected AI backend. The type of data collected depends on the Analyzer you are using. For example, the k8sgpt analyze pod command will collect the following data: - Container status message - Pod name - Pod namespace - Event message","title":"Data we collect"},{"location":"reference/guidelines/privacy/#data-we-share","text":"As mentioned, K8sGPT will share data with the selected AI backend only when you choose --explain and auth against that backend. The data shared will be the same as the data collected. To learn more about the privacy policy of our default AI backend OpenAI please visit their privacy policy .","title":"Data we share"},{"location":"reference/guidelines/privacy/#data-we-protect","text":"When you are sending data through the --explain option, there is the capability of anonymising some of that data. This is done by using the --anonymise flag. In the example of the Deployment Analyzer, this will obfusicate the following data: Deployment name Deployment namespace","title":"Data we protect"},{"location":"reference/guidelines/privacy/#data-we-dont-collect","text":"Logs API Server data other than the primitives used within our Analyzers.","title":"Data we don't collect"},{"location":"reference/guidelines/privacy/#contact","text":"If you have any questions about our privacy policy, please contact us .","title":"Contact"},{"location":"reference/operator/overview/","text":"K8sGPT Operator K8sGPT can run as a Kubernetes Operator inside the cluster. The scan results are provided as Kubernetes YAML manifests. This section will only detail how to configure the operator. For installatio instrusction, please see the getting-started section. Architecture The diagram below showcases the different components that the K8sGPT Operator installs and manages: Customising the Operator As with other Helm Charts, the K8sGPT Operator can be customised by modifying the values.yaml file. The following fields can be customised in the Helm Chart Deployment: Parameter Description Default serviceMonitor.enabled Enable Prometheus Operator ServiceMonitor false controllerManager.manager.image.repository Image repository k8sgpt/k8sgpt-operator controllerManager.manager.image.pullPolicy Image pull policy IfNotPresent controllerManager.manager.imagePullSecrets Image pull secrets [] For example: In-cluster metrics It is possible to enable metrics of the operator so that they can be scraped through Prometheus. This is the configuration required in the values.yaml manifest: serviceMonitor: enabled: true The new values.yaml manifest can then be provided upon installing the Operator inside the cluster: helm install release k8sgpt/k8sgpt-operator --values values.yaml","title":"Overview"},{"location":"reference/operator/overview/#k8sgpt-operator","text":"K8sGPT can run as a Kubernetes Operator inside the cluster. The scan results are provided as Kubernetes YAML manifests. This section will only detail how to configure the operator. For installatio instrusction, please see the getting-started section.","title":"K8sGPT Operator"},{"location":"reference/operator/overview/#architecture","text":"The diagram below showcases the different components that the K8sGPT Operator installs and manages:","title":"Architecture"},{"location":"reference/operator/overview/#customising-the-operator","text":"As with other Helm Charts, the K8sGPT Operator can be customised by modifying the values.yaml file. The following fields can be customised in the Helm Chart Deployment: Parameter Description Default serviceMonitor.enabled Enable Prometheus Operator ServiceMonitor false controllerManager.manager.image.repository Image repository k8sgpt/k8sgpt-operator controllerManager.manager.image.pullPolicy Image pull policy IfNotPresent controllerManager.manager.imagePullSecrets Image pull secrets []","title":"Customising the Operator"},{"location":"reference/operator/overview/#for-example-in-cluster-metrics","text":"It is possible to enable metrics of the operator so that they can be scraped through Prometheus. This is the configuration required in the values.yaml manifest: serviceMonitor: enabled: true The new values.yaml manifest can then be provided upon installing the Operator inside the cluster: helm install release k8sgpt/k8sgpt-operator --values values.yaml","title":"For example: In-cluster metrics"},{"location":"tutorials/","text":"Tutorials This section provides end-to-end tutorials on specific use cases a collection of user and contributor created content","title":"Overview"},{"location":"tutorials/#tutorials","text":"This section provides end-to-end tutorials on specific use cases a collection of user and contributor created content","title":"Tutorials"},{"location":"tutorials/content-collection/content-collection/","text":"Content Collection This section provides a collection of vidoes, blog posts and more on K8sGPT, posted on external sites. Blogs Have a look at the K8sGPT blog on the website. Additionally, here are several blogs created by the community: K8sGPT: The Ultimate Tool for Kubernetes Scanning by Rakshit Gondwal K8sGPT + LocalAI: Unlock Kubernetes superpowers for free! by Tyler Gillson K8sGPT: Simplifying Kubernetes Diagnostics with Natural Language Processing by Karan Singh Kubernetes + ChatGPT = K8sGpt by Vijul Patel ChatGPT for your Kubernetes Cluster \u2014 k8sgpt by Renjith Ravindranathan Using the Trivy K8sGPT plugin by Renjith Ravindranathan Videos Kubernetes + OpenAI = K8sGPT, giving you AI superpowers! k8sgpt Getting Started (2023) Debugging Kubernetes with AI: k8sGPT || AI-Powered Debugging for Kubernetes Contributing If you have created any content around K8sGPT, then please add it to this collection.","title":"Content Collection"},{"location":"tutorials/content-collection/content-collection/#content-collection","text":"This section provides a collection of vidoes, blog posts and more on K8sGPT, posted on external sites.","title":"Content Collection"},{"location":"tutorials/content-collection/content-collection/#blogs","text":"Have a look at the K8sGPT blog on the website. Additionally, here are several blogs created by the community: K8sGPT: The Ultimate Tool for Kubernetes Scanning by Rakshit Gondwal K8sGPT + LocalAI: Unlock Kubernetes superpowers for free! by Tyler Gillson K8sGPT: Simplifying Kubernetes Diagnostics with Natural Language Processing by Karan Singh Kubernetes + ChatGPT = K8sGpt by Vijul Patel ChatGPT for your Kubernetes Cluster \u2014 k8sgpt by Renjith Ravindranathan Using the Trivy K8sGPT plugin by Renjith Ravindranathan","title":"Blogs"},{"location":"tutorials/content-collection/content-collection/#videos","text":"Kubernetes + OpenAI = K8sGPT, giving you AI superpowers! k8sgpt Getting Started (2023) Debugging Kubernetes with AI: k8sGPT || AI-Powered Debugging for Kubernetes","title":"Videos"},{"location":"tutorials/content-collection/content-collection/#contributing","text":"If you have created any content around K8sGPT, then please add it to this collection.","title":"Contributing"}]}